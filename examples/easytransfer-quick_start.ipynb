{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "f9db1dc0-60de-4114-ac7b-caba1b3a4e63"
   },
   "source": [
    "# 使用Jupyter-Notebook快速搭建文本分类应用\n",
    "\n",
    "这是一篇介绍如何在PAI-DSW里用EasyTransfer平台训练文本分类器的教程。只需要一份配置文件，一份ipynb文件，您就可以完成对原始数据的特征提取，网络构建，损失函数及分类评估/预测的简单调用。运行本DEMO需要如下的配置信息\n",
    "\n",
    "- python 3.6+\n",
    "- tensorflow 1.12+\n",
    "\n",
    "## （一）数据准备\n",
    "下面以一个基于bert的文本分类为例，通过端到端的分布式训练/评估/预测流程，展示平台的易用性。这里的端到端指的是直接读入原始数据就可以训练，而不需要事先转换成Bert特征格式。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-09-16 20:43:23--  https://pai-public-data.oss-cn-beijing.aliyuncs.com/public_whl/easytransfer-1.0.0-py3-none-any.whl\n",
      "Resolving pai-public-data.oss-cn-beijing.aliyuncs.com (pai-public-data.oss-cn-beijing.aliyuncs.com)... 59.110.185.63\n",
      "Connecting to pai-public-data.oss-cn-beijing.aliyuncs.com (pai-public-data.oss-cn-beijing.aliyuncs.com)|59.110.185.63|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 179210 (175K) [application/octet-stream]\n",
      "Saving to: ‘easytransfer-1.0.0-py3-none-any.whl’\n",
      "\n",
      "100%[======================================>] 179,210     --.-K/s   in 0.1s    \n",
      "\n",
      "2020-09-16 20:43:23 (1.70 MB/s) - ‘easytransfer-1.0.0-py3-none-any.whl’ saved [179210/179210]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O easytransfer-1.0.0-py3-none-any.whl https://pai-public-data.oss-cn-beijing.aliyuncs.com/public_whl/easytransfer-1.0.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./easytransfer-1.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from easytransfer==1.0.0)\n",
      "Collecting joblib==0.14.1 (from easytransfer==1.0.0)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\n",
      "\u001b[K    100% |████████████████████████████████| 296kB 72.4MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: sklearn in /data/nas/workspace/envs/python3.6/site-packages (from easytransfer==1.0.0)\n",
      "Collecting sentencepiece (from easytransfer==1.0.0)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/68/e5/0366f50a00db181f4b7f3bdc408fc7c4177657f5bf45cb799b79fb4ce15c/sentencepiece-0.1.92-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.2MB 82.7MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /data/nas/workspace/envs/python3.6/site-packages (from easytransfer==1.0.0)\n",
      "Requirement already satisfied: scikit-learn in /data/nas/workspace/envs/python3.6/site-packages (from sklearn->easytransfer==1.0.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /data/nas/workspace/envs/python3.6/site-packages (from scikit-learn->sklearn->easytransfer==1.0.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /data/nas/workspace/envs/python3.6/site-packages (from scikit-learn->sklearn->easytransfer==1.0.0)\n",
      "Installing collected packages: joblib, sentencepiece, easytransfer\n",
      "  Found existing installation: joblib 0.16.0\n",
      "    Uninstalling joblib-0.16.0:\n",
      "      Successfully uninstalled joblib-0.16.0\n",
      "Successfully installed easytransfer-1.0.0 joblib-0.14.1 sentencepiece-0.1.92\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 20.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ./easytransfer-1.0.0-py3-none-any.whl --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "uuid": "c39089e1-d85a-485a-8711-65586b1ddeac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-09-16 20:39:38--  https://atp-modelzoo-sh.oss-cn-shanghai.aliyuncs.com/tutorial/dsw/train.csv\n",
      "Resolving atp-modelzoo-sh.oss-cn-shanghai.aliyuncs.com (atp-modelzoo-sh.oss-cn-shanghai.aliyuncs.com)... 106.14.228.37\n",
      "Connecting to atp-modelzoo-sh.oss-cn-shanghai.aliyuncs.com (atp-modelzoo-sh.oss-cn-shanghai.aliyuncs.com)|106.14.228.37|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6008185 (5.7M) [text/csv]\n",
      "Saving to: ‘./data/train.csv’\n",
      "\n",
      "100%[======================================>] 6,008,185   25.1MB/s   in 0.2s   \n",
      "\n",
      "2020-09-16 20:39:38 (25.1 MB/s) - ‘./data/train.csv’ saved [6008185/6008185]\n",
      "\n",
      "--2020-09-16 20:39:39--  https://atp-modelzoo-sh.oss-cn-shanghai.aliyuncs.com/tutorial/dsw/dev.csv\n",
      "Resolving atp-modelzoo-sh.oss-cn-shanghai.aliyuncs.com (atp-modelzoo-sh.oss-cn-shanghai.aliyuncs.com)... 106.14.228.37\n",
      "Connecting to atp-modelzoo-sh.oss-cn-shanghai.aliyuncs.com (atp-modelzoo-sh.oss-cn-shanghai.aliyuncs.com)|106.14.228.37|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1125139 (1.1M) [text/csv]\n",
      "Saving to: ‘./data/dev.csv’\n",
      "\n",
      "100%[======================================>] 1,125,139   --.-K/s   in 0.07s   \n",
      "\n",
      "2020-09-16 20:39:39 (14.6 MB/s) - ‘./data/dev.csv’ saved [1125139/1125139]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "!wget -O ./data/train.csv https://atp-modelzoo-sh.oss-cn-shanghai.aliyuncs.com/tutorial/dsw/train.csv\n",
    "!wget -O ./data/dev.csv https://atp-modelzoo-sh.oss-cn-shanghai.aliyuncs.com/tutorial/dsw/dev.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "uuid": "16ae9b6a-62ad-4816-bc08-14e3f4727e06"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "uuid": "70a8b996-2a2a-4539-8c65-809cffbc314e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agriculture\t加快产城融合 以科技创新引领新城区建设 新城区,城镇化率,中心城区,科技新城,科技创新\n",
      "agriculture\t9X10米清雅型别墅，大容量简约民宿风，来自美墅建房的诱惑！ 农村,琉璃瓦,民宿,农村自建房,自建房\n",
      "agriculture\t15000亿基建投资！为特色小镇、田园综合体带来哪些新的机遇？ 仙新路,和燕路,南京,总投资,2018年南京市城乡建设计划,高速公路,轨道交通,省干线公路\n",
      "agriculture\t“滞销大爷”家里没滞销水果 原图拍摄者称要维权 店家,著作权,滥用,悲情牌,滞销大爷\n",
      "agriculture\t史上最全经济作物需肥总结 盛期,生育期,营养生长,氧化钾,K2O,需肥量,生长量,硝态氮,五氧化二磷,P2O5\n",
      "agriculture\t植保无人机飞控品牌有哪些？\n",
      "agriculture\t「牛羊催肥」肉羊吃什么饲料催肥增重长得快，一天长7两-1斤 美力盾小杨,旺长素,玉米粒,肉羊,育肥羊\n",
      "agriculture\t农村创业别养猪，今年养猪只剩哭，猪价持续下跌原来是这些原因 养猪,利润率,农村\n",
      "agriculture\t你什么时候回来，不要在大城市打工了 嫁祸于人,农村\n",
      "agriculture\t到底怎样才能称之为田园综合体！\n"
     ]
    }
   ],
   "source": [
    "!head ./data/train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "uuid": "aa8f56c0-db1c-4d0e-803d-976e33786ef2"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/train.csv', header=None, delimiter='\\t', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "uuid": "7699e1a8-1d2b-4a11-9e17-0700dae18636"
   },
   "outputs": [],
   "source": [
    "df.columns = ['label','content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "uuid": "fe9c6f42-9fd8-4227-9c9e-54a5c6e7ba88"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agriculture</td>\n",
       "      <td>加快产城融合 以科技创新引领新城区建设 新城区,城镇化率,中心城区,科技新城,科技创新</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agriculture</td>\n",
       "      <td>9X10米清雅型别墅，大容量简约民宿风，来自美墅建房的诱惑！ 农村,琉璃瓦,民宿,农村自建房...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                            content\n",
       "0  agriculture        加快产城融合 以科技创新引领新城区建设 新城区,城镇化率,中心城区,科技新城,科技创新\n",
       "1  agriculture  9X10米清雅型别墅，大容量简约民宿风，来自美墅建房的诱惑！ 农村,琉璃瓦,民宿,农村自建房..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellType": "code",
    "uuid": "afb86c76-9082-477c-b93a-c041304cbcf7"
   },
   "source": [
    "## （二）定义配置文件\n",
    "\n",
    "如下是我们easytransfe的配置，比如说predict_checkpoint_path是指定验证集上指标最好的checkpoint的路径。\n",
    "详细配置介绍请看easytransfer文档: https://yuque.antfin-inc.com/pai/transfer-learning/zyib3t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "uuid": "2f687623-98d6-4394-b8ce-558070dc8a6d"
   },
   "outputs": [],
   "source": [
    "config_json = {\n",
    "    \"worker_hosts\": \"locahost\",\n",
    "    \"task_index\": 1,\n",
    "    \"job_name\": \"chief\",\n",
    "    \"num_gpus\": 1,\n",
    "    \"num_workers\": 1,\n",
    "    \"modelZooBasePath\": \"/home/admin/jupyter/my_model_zoo\",\n",
    "    \"preprocess_config\": {\n",
    "        \"input_schema\": \"label:str:1,content:str:1\",\n",
    "        \"first_sequence\": \"content\",\n",
    "        \"second_sequence\": None,\n",
    "        \"sequence_length\": 16,\n",
    "        \"label_name\": \"label\",\n",
    "        \"label_enumerate_values\": \"tech,finance,entertainment,world,car,culture,sports,military,edu,game,travel,agriculture,house,story,stock\",\n",
    "        \"output_schema\": \"label,predictions\"\n",
    "    },\n",
    "    \"model_config\": {\n",
    "        \"pretrain_model_name_or_path\": \"pai-bert-tiny-zh\",\n",
    "        \"num_labels\": 15\n",
    "    },\n",
    "    \"train_config\": {\n",
    "        \"train_input_fp\": \"./data/train.csv\",\n",
    "        \"train_batch_size\": 2,\n",
    "        \"num_epochs\": 1,\n",
    "        \"model_dir\": \"model_dir\",\n",
    "        \"optimizer_config\": {\n",
    "            \"learning_rate\": 1e-5\n",
    "        },\n",
    "        \"distribution_config\": {\n",
    "            \"distribution_strategy\": None\n",
    "        }\n",
    "    },\n",
    "    \"evaluate_config\": {\n",
    "        \"eval_input_fp\": \"./data/dev.csv\",\n",
    "        \"eval_batch_size\": 8\n",
    "    },\n",
    "    \"predict_config\": {\n",
    "        \"predict_checkpoint_path\": \"model_dir/model.ckpt-834\",\n",
    "        \"predict_input_fp\": \"./data/dev.csv\",\n",
    "        \"predict_output_fp\": \"./data/predict.csv\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "785e9792-dd80-477b-92c0-0b54e3c94213"
   },
   "source": [
    "##  （三）定义分类应用\n",
    "\n",
    "### 导入ez_transfer库文件\n",
    "- base_model: 所有应用都需要继承的父类\n",
    "- Config：用来解析配置文件的父类\n",
    "- layers：基础组件。比如Embedding，Attention等\n",
    "- model_zoo: 管理预训练模型的组件库，通过get_pretrained_model方法可调用bert模型\n",
    "- preprocessors：管理各种应用的预处理逻辑\n",
    "- CSVReader：csv格式的数据读取器\n",
    "- softmax_cross_entropy：用于分类任务的损失函数\n",
    "- classification_eval_metrics：用于分类任务的评估指标，比如Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "uuid": "10ccec35-4235-4f4a-96a9-85cced4a1eb5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0916 20:44:11.559335 140053906782016 deprecation_wrapper.py:119] From /home/admin/.local/lib/python3.6/site-packages/easytransfer/engines/model.py:22: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "W0916 20:44:11.560436 140053906782016 deprecation_wrapper.py:119] From /home/admin/.local/lib/python3.6/site-packages/easytransfer/engines/model.py:22: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "W0916 20:44:11.561143 140053906782016 deprecation_wrapper.py:119] From /home/admin/.local/lib/python3.6/site-packages/easytransfer/engines/model.py:27: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "W0916 20:44:11.577982 140053906782016 deprecation_wrapper.py:119] From /home/admin/.local/lib/python3.6/site-packages/easytransfer/engines/model.py:28: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from easytransfer import base_model, Config\n",
    "from easytransfer import layers\n",
    "from easytransfer import model_zoo\n",
    "from easytransfer import preprocessors\n",
    "from easytransfer.datasets import CSVReader,CSVWriter\n",
    "from easytransfer.losses import softmax_cross_entropy\n",
    "from easytransfer.evaluators import classification_eval_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "2db018a2-8824-42e8-b357-91b88e148b0f"
   },
   "source": [
    "## 构图\n",
    "完整的训练/评估/预测/链路，由四个函数构成\n",
    "- build_logits: 构图\n",
    "- build_loss：定义损失函数\n",
    "- build_eval_metrics：定义评估指标\n",
    "- build_predictions：定义预测输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "uuid": "91c6db6b-425d-4047-9ebe-f0917c1a7aad"
   },
   "outputs": [],
   "source": [
    "class TextClassification(base_model):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(TextClassification, self).__init__(**kwargs)\n",
    "        self.user_defined_config = kwargs[\"user_defined_config\"]\n",
    "\n",
    "    def build_logits(self, features, mode=None):\n",
    "        # 负责对原始数据进行预处理，生成模型需要的特征，比如：input_ids, input_mask, segment_ids等\n",
    "        preprocessor = preprocessors.get_preprocessor(self.pretrain_model_name_or_path,\n",
    "                                                      user_defined_config=self.user_defined_config)\n",
    "\n",
    "        # 负责构建网络的backbone\n",
    "        model = model_zoo.get_pretrained_model(self.pretrain_model_name_or_path)\n",
    "\n",
    "        dense = layers.Dense(self.num_labels, kernel_initializer=layers.get_initializer(0.02), name='dense')\n",
    "\n",
    "        input_ids, input_mask, segment_ids, label_ids = preprocessor(features)\n",
    "\n",
    "        _, pooled_output = model([input_ids, input_mask, segment_ids], mode=mode)\n",
    "\n",
    "        logits = dense(pooled_output)\n",
    "\n",
    "        return logits, label_ids\n",
    "\n",
    "    def build_loss(self, logits, labels):\n",
    "        return softmax_cross_entropy(labels, self.num_labels, logits)\n",
    "    \n",
    "    def build_eval_metrics(self, logits, labels):\n",
    "        return classification_eval_metrics(logits, labels, self.num_labels)\n",
    "\n",
    "    def build_predictions(self, output):\n",
    "        logits, _ = output\n",
    "        predictions = dict()\n",
    "        predictions[\"predictions\"] = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "c31301bb-0dc0-4506-9c94-73d76942c782"
   },
   "source": [
    "# (四）启动训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "uuid": "32cfce03-786a-434f-9166-7b3649e4f84c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0916 20:44:43.581403 140053906782016 deprecation_wrapper.py:119] From /home/admin/.local/lib/python3.6/site-packages/easytransfer/engines/model.py:61: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "I0916 20:44:43.582599 140053906782016 model.py:61] ***************** modelZooBasePath /home/admin/jupyter/my_model_zoo ***************\n"
     ]
    }
   ],
   "source": [
    "config = Config(mode=\"train_and_evaluate_on_the_fly\", config_json=config_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "uuid": "ec5ad940-9410-4d95-8a17-788c826f18eb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0916 20:44:44.966868 140053906782016 deprecation_wrapper.py:119] From /home/admin/.local/lib/python3.6/site-packages/easytransfer/engines/model.py:731: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "I0916 20:44:45.229859 140053906782016 model.py:736] total number of training examples 53360\n",
      "I0916 20:44:45.230817 140053906782016 model.py:238] ***********Running in train_and_evaluate_on_the_fly mode***********\n",
      "I0916 20:44:45.231338 140053906782016 model.py:247] ***********Disable Tao***********\n",
      "I0916 20:44:45.231803 140053906782016 model.py:254] ***********Disable AUTO_MIXED_PRECISION***********\n",
      "I0916 20:44:45.232288 140053906782016 model.py:265] ***********NCCL_MAX_NRINGS 4***********\n",
      "I0916 20:44:45.232758 140053906782016 model.py:266] ***********NCCL_MIN_NRINGS 4***********\n",
      "I0916 20:44:45.233205 140053906782016 model.py:267] ***********TF_JIT_PROFILING False***********\n",
      "I0916 20:44:45.233658 140053906782016 model.py:268] ***********PAI_ENABLE_HLO_DUMPER False***********\n",
      "I0916 20:44:45.234186 140053906782016 model.py:355] ***********Single worker, Single gpu, Don't use distribution strategy***********\n",
      "I0916 20:44:45.234769 140053906782016 model.py:385] model_dir: model_dir\n",
      "I0916 20:44:45.235219 140053906782016 model.py:386] num workers: 1\n",
      "I0916 20:44:45.235709 140053906782016 model.py:387] num gpus: 1\n",
      "I0916 20:44:45.236136 140053906782016 model.py:388] learning rate: 1e-05\n",
      "I0916 20:44:45.236594 140053906782016 model.py:389] train batch size: 2\n",
      "I0916 20:44:45.237015 140053906782016 model.py:390] global batch size: 2\n",
      "I0916 20:44:45.237458 140053906782016 model.py:391] num accumulated batches: 1\n",
      "I0916 20:44:45.237888 140053906782016 model.py:392] num model replica: 1\n",
      "I0916 20:44:45.238328 140053906782016 model.py:393] num train examples per epoch: 53360\n",
      "I0916 20:44:45.238763 140053906782016 model.py:394] num epochs: 1.0\n",
      "I0916 20:44:45.239190 140053906782016 model.py:395] train steps: 26681\n",
      "I0916 20:44:45.239661 140053906782016 model.py:396] save steps: 26680\n",
      "I0916 20:44:45.240069 140053906782016 model.py:397] throttle secs: 100\n",
      "I0916 20:44:45.240511 140053906782016 model.py:398] keep checkpoint max: 10\n",
      "I0916 20:44:45.240938 140053906782016 model.py:399] warmup ratio: 0.1\n",
      "I0916 20:44:45.241366 140053906782016 model.py:400] gradient clip: True\n",
      "I0916 20:44:45.241807 140053906782016 model.py:401] log step count steps: 100\n",
      "W0916 20:44:45.242329 140053906782016 deprecation_wrapper.py:119] From /home/admin/.local/lib/python3.6/site-packages/easytransfer/engines/model.py:459: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0916 20:44:45.242825 140053906782016 deprecation_wrapper.py:119] From /home/admin/.local/lib/python3.6/site-packages/easytransfer/engines/model.py:464: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
      "\n",
      "I0916 20:44:45.244077 140053906782016 estimator.py:209] Using config: {'_model_dir': 'model_dir', '_tf_random_seed': 123123, '_save_summary_steps': 100, '_save_checkpoints_steps': 26680, '_save_checkpoints_secs': None, '_session_config': intra_op_parallelism_threads: 1024\n",
      "inter_op_parallelism_threads: 1024\n",
      "gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "  allow_growth: true\n",
      "  force_gpu_compatible: true\n",
      "}\n",
      "allow_soft_placement: true\n",
      ", '_keep_checkpoint_max': 10, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6073dea470>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "W0916 20:44:45.250181 140053906782016 model_fn.py:630] Estimator's model_fn (<function EzTransEstimator._build_model_fn.<locals>.model_fn at 0x7f607183b8c8>) includes params argument, but params are not passed to Estimator.\n",
      "I0916 20:44:45.251564 140053906782016 model.py:425] num eval steps: None\n"
     ]
    }
   ],
   "source": [
    "app = TextClassification(user_defined_config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "uuid": "d2578057-a24c-4056-a928-832b0e2f3024"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 20:44:47.737787 140053906782016 reader.py:78] num_parallel_batches 1\n",
      "I0916 20:44:47.739200 140053906782016 reader.py:79] shuffle_buffer_size None\n",
      "I0916 20:44:47.739801 140053906782016 reader.py:80] prefetch_buffer_size 1\n",
      "I0916 20:44:47.740364 140053906782016 reader.py:81] batch_size 2\n",
      "I0916 20:44:47.740909 140053906782016 reader.py:82] distribution_strategy None\n",
      "I0916 20:44:47.741471 140053906782016 reader.py:83] num_micro_batches 1\n",
      "I0916 20:44:47.742014 140053906782016 reader.py:84] input_schema label:str:1,content:str:1\n",
      "I0916 20:44:48.012047 140053906782016 csv_reader.py:54] ./data/train.csv, total number of training examples 53360\n",
      "I0916 20:44:48.012912 140053906782016 reader.py:78] num_parallel_batches 1\n",
      "I0916 20:44:48.013436 140053906782016 reader.py:79] shuffle_buffer_size None\n",
      "I0916 20:44:48.013882 140053906782016 reader.py:80] prefetch_buffer_size 1\n",
      "I0916 20:44:48.014325 140053906782016 reader.py:81] batch_size 8\n",
      "I0916 20:44:48.014764 140053906782016 reader.py:82] distribution_strategy None\n",
      "I0916 20:44:48.015189 140053906782016 reader.py:83] num_micro_batches 1\n",
      "I0916 20:44:48.015644 140053906782016 reader.py:84] input_schema label:str:1,content:str:1\n",
      "I0916 20:44:48.069530 140053906782016 csv_reader.py:59] ./data/dev.csv, total number of eval examples 10000\n"
     ]
    }
   ],
   "source": [
    "train_reader = CSVReader(input_glob=app.train_input_fp,\n",
    "                         is_training=True,\n",
    "                         input_schema=app.input_schema,\n",
    "                         batch_size=app.train_batch_size)\n",
    "\n",
    "eval_reader = CSVReader(input_glob=app.eval_input_fp,\n",
    "                        is_training=False,\n",
    "                        input_schema=app.input_schema,\n",
    "                        batch_size=app.eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "uuid": "84bb64e6-5461-4685-b105-872c6ad01c27"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 20:44:49.485316 140053906782016 estimator_training.py:186] Not using Distribute Coordinator.\n",
      "I0916 20:44:49.486536 140053906782016 training.py:612] Running training and evaluation locally (non-distributed).\n",
      "I0916 20:44:49.487238 140053906782016 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 26680 or save_checkpoints_secs None.\n",
      "W0916 20:44:49.497976 140053906782016 deprecation.py:323] From /opt/conda/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "I0916 20:44:49.532213 140053906782016 reader.py:89] Random shuffle on the whole 53360 training examples\n",
      "W0916 20:44:49.539989 140053906782016 deprecation.py:323] From /opt/conda/lib/python3.6/site-packages/tensorflow/python/data/util/random_seed.py:58: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0916 20:44:49.542621 140053906782016 deprecation.py:323] From /home/admin/.local/lib/python3.6/site-packages/easytransfer/datasets/reader.py:104: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "W0916 20:44:49.544831 140053906782016 deprecation_wrapper.py:119] From /home/admin/.local/lib/python3.6/site-packages/easytransfer/datasets/csv_reader.py:90: The name tf.decode_csv is deprecated. Please use tf.io.decode_csv instead.\n",
      "\n",
      "I0916 20:44:49.565390 140053906782016 estimator.py:1145] Calling model_fn.\n",
      "I0916 20:44:49.583323 140053906782016 preprocessor.py:127] ********** Begin to download to /home/admin/jupyter/my_model_zoo/bert/pai-bert-tiny-zh.tgz **********\n",
      "W0916 20:44:53.510470 140053906782016 deprecation_wrapper.py:119] From /home/admin/.local/lib/python3.6/site-packages/easytransfer/preprocessors/preprocessor.py:143: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n",
      "W0916 20:44:53.512035 140053906782016 deprecation_wrapper.py:119] From /home/admin/.local/lib/python3.6/site-packages/easytransfer/preprocessors/preprocessor.py:144: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n",
      "W0916 20:44:53.522484 140053906782016 deprecation_wrapper.py:119] From /home/admin/.local/lib/python3.6/site-packages/easytransfer/preprocessors/preprocessor.py:147: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.\n",
      "\n",
      "W0916 20:44:53.566992 140053906782016 deprecation_wrapper.py:119] From /home/admin/.local/lib/python3.6/site-packages/easytransfer/preprocessors/tokenization.py:116: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0916 20:44:53.674145 140053906782016 deprecation_wrapper.py:119] From /home/admin/.local/lib/python3.6/site-packages/easytransfer/layers/utils.py:102: The name tf.keras.initializers.TruncatedNormal is deprecated. Please use tf.compat.v1.keras.initializers.TruncatedNormal instead.\n",
      "\n",
      "W0916 20:44:53.675175 140053906782016 deprecation.py:506] From /opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/initializers.py:94: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0916 20:44:55.341547 140053906782016 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "I0916 20:44:58.057471 140053906782016 modeling_utils.py:156] Load weights from /home/admin/jupyter/my_model_zoo/bert/pai-bert-tiny-zh/model.ckpt\n",
      "W0916 20:44:58.058695 140053906782016 deprecation_wrapper.py:119] From /home/admin/.local/lib/python3.6/site-packages/easytransfer/model_zoo/modeling_utils.py:157: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
      "\n",
      "W0916 20:44:58.737160 140053906782016 deprecation.py:323] From /opt/conda/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py:255: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "W0916 20:44:58.741500 140053906782016 deprecation.py:506] From /opt/conda/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py:253: calling string_split (from tensorflow.python.ops.ragged.ragged_string_ops) with delimiter is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "delimiter is deprecated, please use sep instead.\n",
      "W0916 20:44:59.633938 140053906782016 deprecation_wrapper.py:119] From /home/admin/.local/lib/python3.6/site-packages/easytransfer/losses/classification_regression_loss.py:22: The name tf.losses.softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.softmax_cross_entropy instead.\n",
      "\n",
      "W0916 20:44:59.679632 140053906782016 deprecation_wrapper.py:119] From /home/admin/.local/lib/python3.6/site-packages/easytransfer/optimizers/__init__.py:37: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "W0916 20:44:59.680388 140053906782016 deprecation_wrapper.py:119] From /home/admin/.local/lib/python3.6/site-packages/easytransfer/optimizers/__init__.py:39: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
      "\n",
      "W0916 20:44:59.686546 140053906782016 deprecation.py:323] From /opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "I0916 20:44:59.691985 140053906782016 __init__.py:50] *******Warmup 2668 steps***********\n",
      "I0916 20:44:59.701780 140053906782016 __init__.py:77] *******Using adam optimizer************\n",
      "W0916 20:44:59.702383 140053906782016 deprecation_wrapper.py:119] From /home/admin/.local/lib/python3.6/site-packages/easytransfer/optimizers/__init__.py:78: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "I0916 20:45:00.788550 140053906782016 __init__.py:100] *******Num of trainable variables 3223577************\n",
      "I0916 20:45:00.789665 140053906782016 __init__.py:103] *******Clip Gradients************\n",
      "I0916 20:45:00.790193 140053906782016 __init__.py:104] *******Clip Norm Value 1.0*********\n",
      "W0916 20:45:01.666311 140053906782016 deprecation_wrapper.py:119] From /home/admin/.local/lib/python3.6/site-packages/easytransfer/optimizers/__init__.py:122: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "W0916 20:45:01.669149 140053906782016 deprecation_wrapper.py:119] From /home/admin/.local/lib/python3.6/site-packages/easytransfer/utils/hooks.py:20: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
      "\n",
      "W0916 20:45:01.669846 140053906782016 deprecation_wrapper.py:119] From /home/admin/.local/lib/python3.6/site-packages/easytransfer/utils/hooks.py:27: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "W0916 20:45:01.675224 140053906782016 deprecation_wrapper.py:119] From /home/admin/.local/lib/python3.6/site-packages/easytransfer/engines/model.py:518: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "I0916 20:45:01.676994 140053906782016 estimator.py:1147] Done calling model_fn.\n",
      "I0916 20:45:01.680124 140053906782016 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "I0916 20:45:02.590695 140053906782016 monitored_session.py:240] Graph was finalized.\n",
      "I0916 20:45:03.577826 140053906782016 session_manager.py:500] Running local_init_op.\n",
      "I0916 20:45:03.637510 140053906782016 session_manager.py:502] Done running local_init_op.\n",
      "I0916 20:45:06.015580 140053906782016 basic_session_run_hooks.py:606] Saving checkpoints for 0 into model_dir/model.ckpt.\n",
      "I0916 20:45:08.445096 140053906782016 basic_session_run_hooks.py:262] loss = 2.639944, step = 1\n",
      "I0916 20:45:08.446692 140053906782016 hooks.py:51] progress = 0.00%, avg_loss = 2.639944\n",
      "I0916 20:45:28.249738 140053906782016 basic_session_run_hooks.py:692] global_step/sec: 5.04922\n",
      "I0916 20:45:28.251764 140053906782016 basic_session_run_hooks.py:260] loss = 2.7033963, step = 101 (19.807 sec)\n",
      "I0916 20:45:28.252619 140053906782016 hooks.py:51] progress = 0.37%, avg_loss = 2.687408\n",
      "I0916 20:45:47.054001 140053906782016 basic_session_run_hooks.py:692] global_step/sec: 5.31793\n",
      "I0916 20:45:47.056139 140053906782016 basic_session_run_hooks.py:260] loss = 2.794828, step = 201 (18.804 sec)\n",
      "I0916 20:45:47.057114 140053906782016 hooks.py:51] progress = 0.75%, avg_loss = 2.708408\n",
      "I0916 20:46:06.057814 140053906782016 basic_session_run_hooks.py:692] global_step/sec: 5.2621\n",
      "I0916 20:46:06.059584 140053906782016 basic_session_run_hooks.py:260] loss = 2.6555529, step = 301 (19.003 sec)\n",
      "I0916 20:46:06.060398 140053906782016 hooks.py:51] progress = 1.12%, avg_loss = 2.728800\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5f871ed0b6e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_train_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_reader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_reader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_reader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/easytransfer/engines/model.py\u001b[0m in \u001b[0;36mrun_train_and_evaluate\u001b[0;34m(self, train_reader, eval_reader)\u001b[0m\n\u001b[1;32m    567\u001b[0m         tf.estimator.train_and_evaluate(self.estimator,\n\u001b[1;32m    568\u001b[0m                                         \u001b[0mtrain_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m                                         eval_spec=eval_spec)\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/training.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(estimator, train_spec, eval_spec)\u001b[0m\n\u001b[1;32m    471\u001b[0m         '(with task id 0).  Given task id {}'.format(config.task_id))\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/training.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    611\u001b[0m         config.task_type != run_config_lib.TaskType.EVALUATOR):\n\u001b[1;32m    612\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running training and evaluation locally (non-distributed).'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0;31m# Distributed case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/training.py\u001b[0m in \u001b[0;36mrun_local\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_hooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m         saving_listeners=saving_listeners)\n\u001b[0m\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m     eval_result = listener_for_eval.eval_result or _EvalResult(\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1156\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1190\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1191\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1192\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1482\u001b[0m       \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m         \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many_step_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m         run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1250\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m             run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1253\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m         logging.info(\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1336\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1338\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1339\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1409\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m         \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1411\u001b[0;31m         run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "app.run_train_and_evaluate(train_reader=train_reader, eval_reader=eval_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "12ce0aaf-4864-42c8-a6ee-76d871d9dc2e"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
